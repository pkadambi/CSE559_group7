{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "646c58bb-4b54-46a4-b095-b059267804a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dbf9b32-ee4a-4238-b456-1232c188eec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prad/anaconda3/envs/tcrbert/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-12-13 14:26:01.168712: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734125161.180386     382 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734125161.183978     382 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-13 14:26:01.196884: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import tqdm \n",
    "from transformers import BertModel, BertTokenizer\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import datasets \n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "btok = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "bmod = AutoModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained(\"wukevin/tcr-bert\", do_lower_case=False)\n",
    "model = BertModel.from_pretrained(\"wukevin/tcr-bert\")\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "model.to('cuda')\n",
    "model = model.half()\n",
    "    \n",
    "def BERT_embedding(x):\n",
    "    seq = \" \".join(x)\n",
    "    seq = re.sub(r\"[UZOB]\", \"X\", seq)\n",
    "    encoded_input = tokenizer(seq, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84cacd1f-de79-427c-83f0-2487cc6feffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfetr=pd.read_csv('./data/BAP/epi_split/train.csv', header=None)\n",
    "dfete=pd.read_csv('./data/BAP/epi_split/test.csv', header=None)\n",
    "dfetr.columns = ['Epitope', 'TCR', 'Label']\n",
    "dfete.columns = ['Epitope', 'TCR', 'Label']\n",
    "\n",
    "dfttr=pd.read_csv('./data/BAP/tcr_split/train.csv', header=None)\n",
    "dftte=pd.read_csv('./data/BAP/tcr_split/test.csv', header=None)\n",
    "dfttr.columns = ['Epitope', 'TCR', 'Label']\n",
    "dftte.columns = ['Epitope', 'TCR', 'Label']\n",
    "\n",
    "\n",
    "dfho_epi=pd.read_csv('./data/true_hold_out/epitope_split_test.csv', header=None)\n",
    "dfho_tcr=pd.read_csv('./data/true_hold_out/tcr_split_test.csv', header=None)\n",
    "dfho_epi.columns = ['Epitope', 'TCR'] \n",
    "dfho_tcr.columns = ['Epitope', 'TCR']\n",
    "\n",
    "dfemb=pd.read_csv('./data/embedding/TCRrepertoires.csv', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "199b9026-ff38-4be8-be86-ed7099201507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_input_dct(inpdct):\n",
    "    updated_dct = {}\n",
    "    for key, value in inpdct.items():\n",
    "        if len(value.shape)==3:\n",
    "            updated_dct[key] = value.mean(axis=1)\n",
    "        else:\n",
    "            updated_dct[key] = value\n",
    "    return updated_dct\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a041bf4f-a130-4354-b31c-56dc4c52baf7",
   "metadata": {},
   "source": [
    "# Generate the Classification Results for T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "13923a3b-99f6-4fa9-b928-85b0ff16f6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prad/anaconda3/envs/tcrbert/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/home/prad/anaconda3/envs/tcrbert/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/home/prad/anaconda3/envs/tcrbert/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/home/prad/anaconda3/envs/tcrbert/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/home/prad/anaconda3/envs/tcrbert/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/prad/anaconda3/envs/tcrbert/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/prad/anaconda3/envs/tcrbert/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/home/prad/anaconda3/envs/tcrbert/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/home/prad/anaconda3/envs/tcrbert/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/home/prad/anaconda3/envs/tcrbert/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR Metrics:\n",
      "Accuracy: 0.7306\n",
      "ROC AUC: 0.7304\n",
      "F1 Score: 0.7054\n",
      "Precision Score: 0.7761\n",
      "Recall Score: 0.6465\n"
     ]
    }
   ],
   "source": [
    "#---------------------\n",
    "# dct = pkl.load(open('./embT5/epi_train_dct.pkl', 'rb'))\n",
    "# dct = proc_input_dct(dct)\n",
    "# dctte = pkl.load(open('./embT5/epi_test_dct.pkl', 'rb'))\n",
    "# dctte = proc_input_dct(dctte)\n",
    "\n",
    "# y_train = dfetr.Label.values\n",
    "# y_test = dfete.Label.values\n",
    "\n",
    "#---------------------\n",
    "dct = pkl.load(open('./embT5/tcr_train_dct.pkl', 'rb'))\n",
    "dct = proc_input_dct(dct)\n",
    "dctte = pkl.load(open('./embT5/tcr_test_dct.pkl', 'rb'))\n",
    "dctte = proc_input_dct(dctte)\n",
    "\n",
    "y_train = dfttr.Label.values\n",
    "y_test = dftte.Label.values\n",
    "\n",
    "#---------------------\n",
    "X_train = np.concatenate((dct['epi_full'], dct['tcr_full']), axis=1) \n",
    "X_test = np.concatenate((dctte['epi_full'], dctte['tcr_full']), axis=1)\n",
    "# dctte = pkl.load(open('./embT5/epi_test_dct.pkl', 'rb'))\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "# Split data into train and test\n",
    "# Normalize -> PCA -> SVR Pipeline\n",
    "svr_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=50)),\n",
    "#     ('svr', SVC(keprobability=='rbf', class_weight='balanced', probability=True))\n",
    "    ('svr', SVR())\n",
    "])\n",
    "\n",
    "# Fit and predict\n",
    "svr_pipeline.fit(X_train, y_train)\n",
    "y_pred_svr = svr_pipeline.predict(X_test)\n",
    "\n",
    "# Since SVR is a regressor, convert predictions to binary labels for classification metrics\n",
    "y_pred_svr_binary = (y_pred_svr > 0.5).astype(int)\n",
    "\n",
    "# Metrics for SVR\n",
    "accuracy_svr = accuracy_score(y_test, y_pred_svr_binary)\n",
    "rocauc_svr = roc_auc_score(y_test, y_pred_svr_binary)\n",
    "f1_svr = f1_score(y_test, y_pred_svr_binary)\n",
    "prec_score = precision_score(y_test, y_pred_svr_binary)\n",
    "rec_score = recall_score(y_test, y_pred_svr_binary)\n",
    "\n",
    "print(\"SVR Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_svr:.4f}\")\n",
    "print(f\"ROC AUC: {rocauc_svr:.4f}\")\n",
    "print(f\"F1 Score: {f1_svr:.4f}\")\n",
    "print(f\"Precision Score: {prec_score:.4f}\")\n",
    "print(f\"Recall Score: {rec_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "26aa6972-138b-4743-908a-857238b6f714",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prad/anaconda3/envs/tcrbert/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/home/prad/anaconda3/envs/tcrbert/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/home/prad/anaconda3/envs/tcrbert/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/home/prad/anaconda3/envs/tcrbert/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/home/prad/anaconda3/envs/tcrbert/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/prad/anaconda3/envs/tcrbert/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/prad/anaconda3/envs/tcrbert/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/prad/anaconda3/envs/tcrbert/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/home/prad/anaconda3/envs/tcrbert/lib/python3.9/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/home/prad/anaconda3/envs/tcrbert/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/home/prad/anaconda3/envs/tcrbert/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR Metrics:\n",
      "Accuracy: 0.6767\n",
      "ROC AUC: 0.6767\n",
      "F1 Score: 0.6406\n",
      "Precision Score: 0.7212\n",
      "Recall Score: 0.5762\n"
     ]
    }
   ],
   "source": [
    "#---------------------\n",
    "dct = pkl.load(open('./embT5/epi_train_dct.pkl', 'rb'))\n",
    "dct = proc_input_dct(dct)\n",
    "dctte = pkl.load(open('./embT5/epi_test_dct.pkl', 'rb'))\n",
    "dctte = proc_input_dct(dctte)\n",
    "\n",
    "y_train = dfetr.Label.values\n",
    "y_test = dfete.Label.values\n",
    "\n",
    "#---------------------\n",
    "# dct = pkl.load(open('./embT5/tcr_train_dct.pkl', 'rb'))\n",
    "# dct = proc_input_dct(dct)\n",
    "# dctte = pkl.load(open('./embT5/tcr_test_dct.pkl', 'rb'))\n",
    "# dctte = proc_input_dct(dctte)\n",
    "\n",
    "# y_train = dfttr.Label.values\n",
    "# y_test = dftte.Label.values\n",
    "\n",
    "#---------------------\n",
    "X_train = np.concatenate((dct['epi_full'], dct['tcr_full']), axis=1) \n",
    "X_test = np.concatenate((dctte['epi_full'], dctte['tcr_full']), axis=1)\n",
    "# dctte = pkl.load(open('./embT5/epi_test_dct.pkl', 'rb'))\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "# Split data into train and test\n",
    "# Normalize -> PCA -> SVR Pipeline\n",
    "svr_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=50)),\n",
    "#     ('svr', SVC(kernel='rbf', class_weight='balanced', probability=True))\n",
    "    ('svr', SVC())\n",
    "])\n",
    "\n",
    "# Fit and predict\n",
    "svr_pipeline.fit(X_train, y_train)\n",
    "y_pred_svr = svr_pipeline.predict(X_test)\n",
    "\n",
    "# Since SVR is a regressor, convert predictions to binary labels for classification metrics\n",
    "y_pred_svr_binary = (y_pred_svr > 0.5).astype(int)\n",
    "\n",
    "# Metrics for SVR\n",
    "accuracy_svr = accuracy_score(y_test, y_pred_svr_binary)\n",
    "rocauc_svr = roc_auc_score(y_test, y_pred_svr_binary)\n",
    "f1_svr = f1_score(y_test, y_pred_svr_binary)\n",
    "prec_score = precision_score(y_test, y_pred_svr_binary)\n",
    "rec_score = recall_score(y_test, y_pred_svr_binary)\n",
    "\n",
    "print(\"SVR Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_svr:.4f}\")\n",
    "print(f\"ROC AUC: {rocauc_svr:.4f}\")\n",
    "print(f\"F1 Score: {f1_svr:.4f}\")\n",
    "print(f\"Precision Score: {prec_score:.4f}\")\n",
    "print(f\"Recall Score: {rec_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4154bb-5b46-48c4-b4b8-169cedb43a90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt251",
   "language": "python",
   "name": "pt251"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
